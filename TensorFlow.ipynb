{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST via TensorFlow #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "with gzip.open('./data/fashion-mnist.pkl.gz', 'rb') as fp:\n",
    "    (train_images, train_labels, test_images, test_labels) = \\\n",
    "    _pickle.load(fp)\n",
    "print('Tensorflow version ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_reshape = train_images.reshape(train_images.shape[0],\n",
    "                                            28, 28, 1)\n",
    "test_images_reshape = test_images.reshape(test_images.shape[0],\n",
    "                                         28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplistic Network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.2311 - accuracy: 0.9140 - val_loss: 0.3410 - val_accuracy: 0.8809\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.2254 - accuracy: 0.9162 - val_loss: 0.3270 - val_accuracy: 0.8884\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.2165 - accuracy: 0.9190 - val_loss: 0.3421 - val_accuracy: 0.8838\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2112 - accuracy: 0.9208 - val_loss: 0.3510 - val_accuracy: 0.8758\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2055 - accuracy: 0.9221 - val_loss: 0.3386 - val_accuracy: 0.8913\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1989 - accuracy: 0.9263 - val_loss: 0.3427 - val_accuracy: 0.8863\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1957 - accuracy: 0.9265 - val_loss: 0.3518 - val_accuracy: 0.8836\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1913 - accuracy: 0.9275 - val_loss: 0.3776 - val_accuracy: 0.8783\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1839 - accuracy: 0.9313 - val_loss: 0.3764 - val_accuracy: 0.8799\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1801 - accuracy: 0.9315 - val_loss: 0.3446 - val_accuracy: 0.8925\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1773 - accuracy: 0.9339 - val_loss: 0.3517 - val_accuracy: 0.8914\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1711 - accuracy: 0.9361 - val_loss: 0.3809 - val_accuracy: 0.8814\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1676 - accuracy: 0.9372 - val_loss: 0.3785 - val_accuracy: 0.8858\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1637 - accuracy: 0.9386 - val_loss: 0.3748 - val_accuracy: 0.8811\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1604 - accuracy: 0.9400 - val_loss: 0.3948 - val_accuracy: 0.8882\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1565 - accuracy: 0.9410 - val_loss: 0.3721 - val_accuracy: 0.8906\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1548 - accuracy: 0.9422 - val_loss: 0.4103 - val_accuracy: 0.8783\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1506 - accuracy: 0.9435 - val_loss: 0.3874 - val_accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.1476 - accuracy: 0.9444 - val_loss: 0.4024 - val_accuracy: 0.8849\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1452 - accuracy: 0.9456 - val_loss: 0.3866 - val_accuracy: 0.8891\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1410 - accuracy: 0.9468 - val_loss: 0.4029 - val_accuracy: 0.8859\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1378 - accuracy: 0.9482 - val_loss: 0.4128 - val_accuracy: 0.8890\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1374 - accuracy: 0.9484 - val_loss: 0.4231 - val_accuracy: 0.8861\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1308 - accuracy: 0.9515 - val_loss: 0.4518 - val_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1328 - accuracy: 0.9501 - val_loss: 0.4310 - val_accuracy: 0.8873\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1262 - accuracy: 0.9528 - val_loss: 0.4243 - val_accuracy: 0.8914\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1270 - accuracy: 0.9517 - val_loss: 0.4247 - val_accuracy: 0.8901\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.1217 - accuracy: 0.9550 - val_loss: 0.4335 - val_accuracy: 0.8887\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1212 - accuracy: 0.9552 - val_loss: 0.5050 - val_accuracy: 0.8810\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1191 - accuracy: 0.9551 - val_loss: 0.4520 - val_accuracy: 0.8886\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1156 - accuracy: 0.9565 - val_loss: 0.4803 - val_accuracy: 0.8840\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1148 - accuracy: 0.9574 - val_loss: 0.4479 - val_accuracy: 0.8843\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1129 - accuracy: 0.9577 - val_loss: 0.4538 - val_accuracy: 0.8854\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1126 - accuracy: 0.9579 - val_loss: 0.4939 - val_accuracy: 0.8835\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1077 - accuracy: 0.9600 - val_loss: 0.4799 - val_accuracy: 0.8856\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1053 - accuracy: 0.9607 - val_loss: 0.4754 - val_accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1078 - accuracy: 0.9597 - val_loss: 0.5139 - val_accuracy: 0.8840\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1039 - accuracy: 0.9615 - val_loss: 0.4774 - val_accuracy: 0.8874\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1037 - accuracy: 0.9610 - val_loss: 0.4776 - val_accuracy: 0.8894\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1010 - accuracy: 0.9622 - val_loss: 0.5233 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0992 - accuracy: 0.9624 - val_loss: 0.5013 - val_accuracy: 0.8906\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0991 - accuracy: 0.9631 - val_loss: 0.5074 - val_accuracy: 0.8906\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0965 - accuracy: 0.9638 - val_loss: 0.5333 - val_accuracy: 0.8804\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0940 - accuracy: 0.9650 - val_loss: 0.5446 - val_accuracy: 0.8839\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.0905 - accuracy: 0.9661 - val_loss: 0.5336 - val_accuracy: 0.8859\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 5s 92us/sample - loss: 0.0922 - accuracy: 0.9651 - val_loss: 0.5557 - val_accuracy: 0.8879\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.0930 - accuracy: 0.9646 - val_loss: 0.5405 - val_accuracy: 0.8860\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0884 - accuracy: 0.9666 - val_loss: 0.5824 - val_accuracy: 0.8737\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0862 - accuracy: 0.9682 - val_loss: 0.5790 - val_accuracy: 0.8856\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0871 - accuracy: 0.9672 - val_loss: 0.5757 - val_accuracy: 0.8883\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0859 - accuracy: 0.9680 - val_loss: 0.5717 - val_accuracy: 0.8883\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0835 - accuracy: 0.9691 - val_loss: 0.5991 - val_accuracy: 0.8811\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0850 - accuracy: 0.9678 - val_loss: 0.5700 - val_accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0788 - accuracy: 0.9704 - val_loss: 0.5881 - val_accuracy: 0.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0813 - accuracy: 0.9700 - val_loss: 0.5775 - val_accuracy: 0.8851\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0786 - accuracy: 0.9709 - val_loss: 0.6082 - val_accuracy: 0.8806\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.5760 - val_accuracy: 0.8871\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0783 - accuracy: 0.9710 - val_loss: 0.6150 - val_accuracy: 0.8864\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0750 - accuracy: 0.9718 - val_loss: 0.6382 - val_accuracy: 0.8863\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0753 - accuracy: 0.9718 - val_loss: 0.6226 - val_accuracy: 0.8860\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0744 - accuracy: 0.9716 - val_loss: 0.5923 - val_accuracy: 0.8881\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0753 - accuracy: 0.9710 - val_loss: 0.6103 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0718 - accuracy: 0.9723 - val_loss: 0.6511 - val_accuracy: 0.8828\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0733 - accuracy: 0.9729 - val_loss: 0.6137 - val_accuracy: 0.8897\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0695 - accuracy: 0.9743 - val_loss: 0.6705 - val_accuracy: 0.8829\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.6558 - val_accuracy: 0.8841\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0684 - accuracy: 0.9748 - val_loss: 0.6895 - val_accuracy: 0.8814\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0697 - accuracy: 0.9736 - val_loss: 0.6653 - val_accuracy: 0.8862\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0661 - accuracy: 0.9757 - val_loss: 0.6659 - val_accuracy: 0.8851\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0683 - accuracy: 0.9746 - val_loss: 0.6803 - val_accuracy: 0.8832\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0671 - accuracy: 0.9742 - val_loss: 0.6707 - val_accuracy: 0.8816\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0646 - accuracy: 0.9761 - val_loss: 0.7250 - val_accuracy: 0.8785\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.0656 - accuracy: 0.9755 - val_loss: 0.6818 - val_accuracy: 0.8852\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0655 - accuracy: 0.9756 - val_loss: 0.7122 - val_accuracy: 0.8792\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.0604 - accuracy: 0.9772 - val_loss: 0.7211 - val_accuracy: 0.8845\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0619 - accuracy: 0.9767 - val_loss: 0.7563 - val_accuracy: 0.8823\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0630 - accuracy: 0.9760 - val_loss: 0.7214 - val_accuracy: 0.8870\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0594 - accuracy: 0.9781 - val_loss: 0.7221 - val_accuracy: 0.8844\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0590 - accuracy: 0.9774 - val_loss: 0.6948 - val_accuracy: 0.8840\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0601 - accuracy: 0.9777 - val_loss: 0.7639 - val_accuracy: 0.8794\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0594 - accuracy: 0.9780 - val_loss: 0.7332 - val_accuracy: 0.8859\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0579 - accuracy: 0.9786 - val_loss: 0.7503 - val_accuracy: 0.8822\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0571 - accuracy: 0.9785 - val_loss: 0.7465 - val_accuracy: 0.8853\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0562 - accuracy: 0.9791 - val_loss: 0.7904 - val_accuracy: 0.8803\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0579 - accuracy: 0.9786 - val_loss: 0.7367 - val_accuracy: 0.8824\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0569 - accuracy: 0.9792 - val_loss: 0.7945 - val_accuracy: 0.8842\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0544 - accuracy: 0.9796 - val_loss: 0.7636 - val_accuracy: 0.8844\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0515 - accuracy: 0.9805 - val_loss: 0.7413 - val_accuracy: 0.8882\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0542 - accuracy: 0.9791 - val_loss: 0.7969 - val_accuracy: 0.8868\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0545 - accuracy: 0.9800 - val_loss: 0.7940 - val_accuracy: 0.8856\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.7833 - val_accuracy: 0.8832\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.8185 - val_accuracy: 0.8842\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.0487 - accuracy: 0.9815 - val_loss: 0.7652 - val_accuracy: 0.8856\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.0531 - accuracy: 0.9802 - val_loss: 0.7997 - val_accuracy: 0.8851\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.0515 - accuracy: 0.9812 - val_loss: 0.8445 - val_accuracy: 0.8798\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.8684 - val_accuracy: 0.8839\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0510 - accuracy: 0.9812 - val_loss: 0.8168 - val_accuracy: 0.8840\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.0507 - accuracy: 0.9809 - val_loss: 0.8084 - val_accuracy: 0.8849\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0478 - accuracy: 0.9823 - val_loss: 0.8352 - val_accuracy: 0.8836\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0497 - accuracy: 0.9815 - val_loss: 0.8393 - val_accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x219ca42d048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          epochs=100,\n",
    "          callbacks=[TensorBoard(\n",
    "              log_dir=os.path.join('fitlog', 'simple'),\n",
    "              histogram_freq=1,\n",
    "              profile_batch = 100000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 10700."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir fitlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Conv2D(32, [3, 3], input_shape=(28, 28, 1), activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Conv2D(32, [3, 3], activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, [3, 3], activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Conv2D(64, [3, 3], activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    AveragePooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 597,738\n",
      "Trainable params: 596,330\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 285s 5ms/sample - loss: 0.5293 - accuracy: 0.8159 - val_loss: 0.3812 - val_accuracy: 0.8646\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 272s 5ms/sample - loss: 0.3488 - accuracy: 0.8741 - val_loss: 0.2859 - val_accuracy: 0.8959\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 272s 5ms/sample - loss: 0.3074 - accuracy: 0.8917 - val_loss: 0.2873 - val_accuracy: 0.8928\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 241s 4ms/sample - loss: 0.2779 - accuracy: 0.9010 - val_loss: 0.2543 - val_accuracy: 0.9093\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 266s 4ms/sample - loss: 0.2578 - accuracy: 0.9070 - val_loss: 0.2425 - val_accuracy: 0.9080\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 193s 3ms/sample - loss: 0.2423 - accuracy: 0.9132 - val_loss: 0.2341 - val_accuracy: 0.9144\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 203s 3ms/sample - loss: 0.2272 - accuracy: 0.9181 - val_loss: 0.2179 - val_accuracy: 0.9224\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 191s 3ms/sample - loss: 0.2173 - accuracy: 0.9222 - val_loss: 0.2230 - val_accuracy: 0.9206\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 194s 3ms/sample - loss: 0.2077 - accuracy: 0.9240 - val_loss: 0.2067 - val_accuracy: 0.9277\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1992 - accuracy: 0.9278 - val_loss: 0.2126 - val_accuracy: 0.9240\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 188s 3ms/sample - loss: 0.1899 - accuracy: 0.9307 - val_loss: 0.2103 - val_accuracy: 0.9267\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 187s 3ms/sample - loss: 0.1813 - accuracy: 0.9340 - val_loss: 0.2587 - val_accuracy: 0.9143\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1747 - accuracy: 0.9362 - val_loss: 0.2001 - val_accuracy: 0.9306\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 188s 3ms/sample - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.2385 - val_accuracy: 0.9195\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 192s 3ms/sample - loss: 0.1686 - accuracy: 0.9391 - val_loss: 0.2151 - val_accuracy: 0.9273\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 212s 4ms/sample - loss: 0.1620 - accuracy: 0.9409 - val_loss: 0.2074 - val_accuracy: 0.9278\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 199s 3ms/sample - loss: 0.1573 - accuracy: 0.9426 - val_loss: 0.2067 - val_accuracy: 0.9300\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 194s 3ms/sample - loss: 0.1551 - accuracy: 0.9446 - val_loss: 0.2061 - val_accuracy: 0.9298\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 189s 3ms/sample - loss: 0.1500 - accuracy: 0.9454 - val_loss: 0.1977 - val_accuracy: 0.9309\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 186s 3ms/sample - loss: 0.1481 - accuracy: 0.9464 - val_loss: 0.2124 - val_accuracy: 0.9306\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 186s 3ms/sample - loss: 0.1426 - accuracy: 0.9477 - val_loss: 0.1980 - val_accuracy: 0.9319\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 187s 3ms/sample - loss: 0.1386 - accuracy: 0.9481 - val_loss: 0.2014 - val_accuracy: 0.9315\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1384 - accuracy: 0.9493 - val_loss: 0.2074 - val_accuracy: 0.9320\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1338 - accuracy: 0.9507 - val_loss: 0.2040 - val_accuracy: 0.9346\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1306 - accuracy: 0.9517 - val_loss: 0.2074 - val_accuracy: 0.9316\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1277 - accuracy: 0.9523 - val_loss: 0.1935 - val_accuracy: 0.9359\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 192s 3ms/sample - loss: 0.1295 - accuracy: 0.9527 - val_loss: 0.2384 - val_accuracy: 0.9242\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1260 - accuracy: 0.9537 - val_loss: 0.1981 - val_accuracy: 0.9366\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 192s 3ms/sample - loss: 0.1196 - accuracy: 0.9560 - val_loss: 0.2130 - val_accuracy: 0.9329\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1227 - accuracy: 0.9550 - val_loss: 0.1998 - val_accuracy: 0.9358\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 190s 3ms/sample - loss: 0.1183 - accuracy: 0.9568 - val_loss: 0.2087 - val_accuracy: 0.9334\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 186s 3ms/sample - loss: 0.1143 - accuracy: 0.9575 - val_loss: 0.2064 - val_accuracy: 0.9357\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 184s 3ms/sample - loss: 0.1131 - accuracy: 0.9582 - val_loss: 0.1970 - val_accuracy: 0.9361\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 185s 3ms/sample - loss: 0.1113 - accuracy: 0.9598 - val_loss: 0.2058 - val_accuracy: 0.9354\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 183s 3ms/sample - loss: 0.1083 - accuracy: 0.9606 - val_loss: 0.2141 - val_accuracy: 0.9355\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.1090 - accuracy: 0.9609 - val_loss: 0.2182 - val_accuracy: 0.9327\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.1067 - accuracy: 0.9612 - val_loss: 0.2045 - val_accuracy: 0.9351\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 189s 3ms/sample - loss: 0.1060 - accuracy: 0.9620 - val_loss: 0.2149 - val_accuracy: 0.9331\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 188s 3ms/sample - loss: 0.1044 - accuracy: 0.9610 - val_loss: 0.2110 - val_accuracy: 0.9360\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 187s 3ms/sample - loss: 0.1025 - accuracy: 0.9622 - val_loss: 0.2287 - val_accuracy: 0.9339\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 181s 3ms/sample - loss: 0.1035 - accuracy: 0.9623 - val_loss: 0.2017 - val_accuracy: 0.9356\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0978 - accuracy: 0.9646 - val_loss: 0.2091 - val_accuracy: 0.9351\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.1003 - accuracy: 0.9635 - val_loss: 0.2076 - val_accuracy: 0.9361\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0951 - accuracy: 0.9650 - val_loss: 0.2281 - val_accuracy: 0.9330\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0954 - accuracy: 0.9653 - val_loss: 0.2290 - val_accuracy: 0.9361\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0937 - accuracy: 0.9657 - val_loss: 0.2265 - val_accuracy: 0.9344\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0955 - accuracy: 0.9658 - val_loss: 0.2278 - val_accuracy: 0.9370\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.2130 - val_accuracy: 0.9382\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0911 - accuracy: 0.9662 - val_loss: 0.2147 - val_accuracy: 0.9368\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.2172 - val_accuracy: 0.9377\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0886 - accuracy: 0.9673 - val_loss: 0.2255 - val_accuracy: 0.9370\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 181s 3ms/sample - loss: 0.0892 - accuracy: 0.9683 - val_loss: 0.2289 - val_accuracy: 0.9385\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0877 - accuracy: 0.9685 - val_loss: 0.2301 - val_accuracy: 0.9339\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.0881 - accuracy: 0.9677 - val_loss: 0.2194 - val_accuracy: 0.9421\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 187s 3ms/sample - loss: 0.0870 - accuracy: 0.9675 - val_loss: 0.2142 - val_accuracy: 0.9392\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 183s 3ms/sample - loss: 0.0810 - accuracy: 0.9701 - val_loss: 0.2325 - val_accuracy: 0.9341\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 181s 3ms/sample - loss: 0.0845 - accuracy: 0.9692 - val_loss: 0.2197 - val_accuracy: 0.9366\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0838 - accuracy: 0.9688 - val_loss: 0.2303 - val_accuracy: 0.9355\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0826 - accuracy: 0.9696 - val_loss: 0.2299 - val_accuracy: 0.9377\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0825 - accuracy: 0.9704 - val_loss: 0.2231 - val_accuracy: 0.9369\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0800 - accuracy: 0.9707 - val_loss: 0.2240 - val_accuracy: 0.9372\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 180s 3ms/sample - loss: 0.0777 - accuracy: 0.9707 - val_loss: 0.2295 - val_accuracy: 0.9386\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 177s 3ms/sample - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.2398 - val_accuracy: 0.9371\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 178s 3ms/sample - loss: 0.0790 - accuracy: 0.9712 - val_loss: 0.2340 - val_accuracy: 0.9382\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 169s 3ms/sample - loss: 0.0788 - accuracy: 0.9710 - val_loss: 0.2394 - val_accuracy: 0.9352\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 161s 3ms/sample - loss: 0.0798 - accuracy: 0.9714 - val_loss: 0.2447 - val_accuracy: 0.9385\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 162s 3ms/sample - loss: 0.0762 - accuracy: 0.9717 - val_loss: 0.2496 - val_accuracy: 0.9356\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 160s 3ms/sample - loss: 0.0779 - accuracy: 0.9713 - val_loss: 0.2468 - val_accuracy: 0.9350\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 18721s 312ms/sample - loss: 0.0753 - accuracy: 0.9729 - val_loss: 0.2401 - val_accuracy: 0.9389\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 159s 3ms/sample - loss: 0.0806 - accuracy: 0.9713 - val_loss: 0.2276 - val_accuracy: 0.9375\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 157s 3ms/sample - loss: 0.0760 - accuracy: 0.9723 - val_loss: 0.2309 - val_accuracy: 0.9403\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 156s 3ms/sample - loss: 0.0755 - accuracy: 0.9727 - val_loss: 0.2215 - val_accuracy: 0.9398\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 9183s 153ms/sample - loss: 0.0721 - accuracy: 0.9730 - val_loss: 0.2368 - val_accuracy: 0.9394\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 162s 3ms/sample - loss: 0.0738 - accuracy: 0.9726 - val_loss: 0.2258 - val_accuracy: 0.9372\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 163s 3ms/sample - loss: 0.0703 - accuracy: 0.9742 - val_loss: 0.2471 - val_accuracy: 0.9387\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 162s 3ms/sample - loss: 0.0741 - accuracy: 0.9721 - val_loss: 0.2337 - val_accuracy: 0.9344\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12504s 208ms/sample - loss: 0.0749 - accuracy: 0.9733 - val_loss: 0.2227 - val_accuracy: 0.9402\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 213s 4ms/sample - loss: 0.0719 - accuracy: 0.9744 - val_loss: 0.2449 - val_accuracy: 0.9352\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 223s 4ms/sample - loss: 0.0725 - accuracy: 0.9733 - val_loss: 0.2406 - val_accuracy: 0.9370\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 224s 4ms/sample - loss: 0.0703 - accuracy: 0.9743 - val_loss: 0.2568 - val_accuracy: 0.9386\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 221s 4ms/sample - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.2339 - val_accuracy: 0.9414\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 231s 4ms/sample - loss: 0.0692 - accuracy: 0.9750 - val_loss: 0.2427 - val_accuracy: 0.9376\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 245s 4ms/sample - loss: 0.0695 - accuracy: 0.9749 - val_loss: 0.2355 - val_accuracy: 0.9376\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 170s 3ms/sample - loss: 0.0669 - accuracy: 0.9759 - val_loss: 0.2476 - val_accuracy: 0.9380\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 175s 3ms/sample - loss: 0.0702 - accuracy: 0.9747 - val_loss: 0.2419 - val_accuracy: 0.9386\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 170s 3ms/sample - loss: 0.0684 - accuracy: 0.9749 - val_loss: 0.2504 - val_accuracy: 0.9392\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1089s 18ms/sample - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.2686 - val_accuracy: 0.9389\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 219s 4ms/sample - loss: 0.0684 - accuracy: 0.9751 - val_loss: 0.2665 - val_accuracy: 0.9391\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 173s 3ms/sample - loss: 0.0677 - accuracy: 0.9754 - val_loss: 0.2394 - val_accuracy: 0.9399\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 179s 3ms/sample - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.2486 - val_accuracy: 0.9391\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 192s 3ms/sample - loss: 0.0675 - accuracy: 0.9755 - val_loss: 0.2423 - val_accuracy: 0.9408\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 195s 3ms/sample - loss: 0.0649 - accuracy: 0.9761 - val_loss: 0.2574 - val_accuracy: 0.9385\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 192s 3ms/sample - loss: 0.0667 - accuracy: 0.9762 - val_loss: 0.2512 - val_accuracy: 0.9386\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 195s 3ms/sample - loss: 0.0620 - accuracy: 0.9776 - val_loss: 0.2573 - val_accuracy: 0.9373\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 212s 4ms/sample - loss: 0.0629 - accuracy: 0.9773 - val_loss: 0.2486 - val_accuracy: 0.9402\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 259s 4ms/sample - loss: 0.0625 - accuracy: 0.9768 - val_loss: 0.2550 - val_accuracy: 0.9388\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 260s 4ms/sample - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.2466 - val_accuracy: 0.9401\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 262s 4ms/sample - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.2518 - val_accuracy: 0.9395\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 284s 5ms/sample - loss: 0.0632 - accuracy: 0.9775 - val_loss: 0.2522 - val_accuracy: 0.9358\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 382s 6ms/sample - loss: 0.0619 - accuracy: 0.9775 - val_loss: 0.2687 - val_accuracy: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x219ca5aee88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_images_reshape,\n",
    "          train_labels,\n",
    "          validation_data=(test_images_reshape, test_labels),\n",
    "          epochs=100,\n",
    "          batch_size=25,\n",
    "          callbacks=[TensorBoard(\n",
    "              log_dir=os.path.join('fitlog','thin'),\n",
    "              histogram_freq=1,\n",
    "              profile_batch=100000000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personal best of\n",
    "* loss: 0.1303\n",
    "* acc: 0.9526\n",
    "* val_loss: 0.2367\n",
    "* val_acc: 0.9252\n",
    "\n",
    "with a NN over 25 epochs:\n",
    "* 2d CNN 32 (3, 3) relu\n",
    "* normalization, axis=-1\n",
    "* 2d CNN 32 (3, 3) relu\n",
    "* normalization, axis=-1\n",
    "* 2d max pooling (2, 2)\n",
    "* dropout p = 0.25\n",
    "* 2d CNN 64 (3, 3) relu\n",
    "* normalization, axis=-1\n",
    "* 2d CNN 64 (3, 3) relu\n",
    "* normalization, axis=-1\n",
    "* 2d max pooling (2, 2)\n",
    "* dropout p = 0.25\n",
    "* flatten\n",
    "* dense 512 relu\n",
    "* normalization\n",
    "* dropout p = 0.5\n",
    "* dense 10 softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is clearly overfitting, going to try some regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "    BatchNormalization(axis=-1, input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, [3, 3],\n",
    "           activation='relu',\n",
    "          bias_initializer='RandomNormal',\n",
    "          kernel_initializer='random_uniform'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Conv2D(512, [3, 3],\n",
    "           activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128,\n",
    "          activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 512)       295424    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 11, 11, 512)       2048      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,945,550\n",
      "Trainable params: 1,944,524\n",
      "Non-trainable params: 1,026\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 415s 7ms/sample - loss: 0.5886 - accuracy: 0.7904 - val_loss: 0.3629 - val_accuracy: 0.8677\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 480s 8ms/sample - loss: 0.3897 - accuracy: 0.8640 - val_loss: 0.3405 - val_accuracy: 0.8804\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 440s 7ms/sample - loss: 0.3395 - accuracy: 0.8815 - val_loss: 0.3050 - val_accuracy: 0.8901\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 432s 7ms/sample - loss: 0.3072 - accuracy: 0.8907 - val_loss: 0.2987 - val_accuracy: 0.8939\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 425s 7ms/sample - loss: 0.2874 - accuracy: 0.8967 - val_loss: 0.2981 - val_accuracy: 0.8891\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 423s 7ms/sample - loss: 0.2689 - accuracy: 0.9049 - val_loss: 0.2779 - val_accuracy: 0.9021\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 426s 7ms/sample - loss: 0.2514 - accuracy: 0.9105 - val_loss: 0.2954 - val_accuracy: 0.8915\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 454s 8ms/sample - loss: 0.2405 - accuracy: 0.9140 - val_loss: 0.2632 - val_accuracy: 0.9053\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 441s 7ms/sample - loss: 0.2298 - accuracy: 0.9182 - val_loss: 0.2855 - val_accuracy: 0.9034\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 417s 7ms/sample - loss: 0.2145 - accuracy: 0.9225 - val_loss: 0.2780 - val_accuracy: 0.9081\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 449s 7ms/sample - loss: 0.2086 - accuracy: 0.9252 - val_loss: 0.2878 - val_accuracy: 0.9030\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 435s 7ms/sample - loss: 0.2001 - accuracy: 0.9285 - val_loss: 0.2759 - val_accuracy: 0.9082\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 426s 7ms/sample - loss: 0.1936 - accuracy: 0.9317 - val_loss: 0.2916 - val_accuracy: 0.9082\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 422s 7ms/sample - loss: 0.1805 - accuracy: 0.9357 - val_loss: 0.2930 - val_accuracy: 0.9125\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 435s 7ms/sample - loss: 0.1817 - accuracy: 0.9350 - val_loss: 0.2926 - val_accuracy: 0.9064\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 439s 7ms/sample - loss: 0.1697 - accuracy: 0.9394 - val_loss: 0.3002 - val_accuracy: 0.9117\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 352s 6ms/sample - loss: 0.1660 - accuracy: 0.9418 - val_loss: 0.3083 - val_accuracy: 0.9124\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 319s 5ms/sample - loss: 0.1616 - accuracy: 0.9422 - val_loss: 0.3189 - val_accuracy: 0.9128\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 316s 5ms/sample - loss: 0.1543 - accuracy: 0.9446 - val_loss: 0.3085 - val_accuracy: 0.9151\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 328s 5ms/sample - loss: 0.1526 - accuracy: 0.9459 - val_loss: 0.3007 - val_accuracy: 0.9169\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 337s 6ms/sample - loss: 0.1487 - accuracy: 0.9473 - val_loss: 0.3236 - val_accuracy: 0.9146\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 336s 6ms/sample - loss: 0.1439 - accuracy: 0.9491 - val_loss: 0.3191 - val_accuracy: 0.9185\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 337s 6ms/sample - loss: 0.1410 - accuracy: 0.9501 - val_loss: 0.3258 - val_accuracy: 0.9168\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 335s 6ms/sample - loss: 0.1335 - accuracy: 0.9530 - val_loss: 0.3727 - val_accuracy: 0.9102\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 327s 5ms/sample - loss: 0.1311 - accuracy: 0.9536 - val_loss: 0.3612 - val_accuracy: 0.9065\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 323s 5ms/sample - loss: 0.1303 - accuracy: 0.9548 - val_loss: 0.3296 - val_accuracy: 0.9189\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 323s 5ms/sample - loss: 0.1271 - accuracy: 0.9555 - val_loss: 0.3549 - val_accuracy: 0.9105\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 327s 5ms/sample - loss: 0.1212 - accuracy: 0.9566 - val_loss: 0.3492 - val_accuracy: 0.9178\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 336s 6ms/sample - loss: 0.1203 - accuracy: 0.9579 - val_loss: 0.3751 - val_accuracy: 0.9135\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 337s 6ms/sample - loss: 0.1163 - accuracy: 0.9590 - val_loss: 0.3623 - val_accuracy: 0.9189\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 413s 7ms/sample - loss: 0.1162 - accuracy: 0.9596 - val_loss: 0.3836 - val_accuracy: 0.9194\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 422s 7ms/sample - loss: 0.1120 - accuracy: 0.9606 - val_loss: 0.3912 - val_accuracy: 0.9155\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 422s 7ms/sample - loss: 0.1145 - accuracy: 0.9606 - val_loss: 0.3653 - val_accuracy: 0.9164\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 383s 6ms/sample - loss: 0.1103 - accuracy: 0.9618 - val_loss: 0.3962 - val_accuracy: 0.9133\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 320s 5ms/sample - loss: 0.1082 - accuracy: 0.9630 - val_loss: 0.4450 - val_accuracy: 0.9177\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 321s 5ms/sample - loss: 0.1066 - accuracy: 0.9639 - val_loss: 0.4131 - val_accuracy: 0.9186\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 324s 5ms/sample - loss: 0.1009 - accuracy: 0.9644 - val_loss: 0.4030 - val_accuracy: 0.9189\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 327s 5ms/sample - loss: 0.1002 - accuracy: 0.9660 - val_loss: 0.3908 - val_accuracy: 0.9140\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 338s 6ms/sample - loss: 0.0992 - accuracy: 0.9657 - val_loss: 0.4207 - val_accuracy: 0.9162\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 301s 5ms/sample - loss: 0.1015 - accuracy: 0.9662 - val_loss: 0.4323 - val_accuracy: 0.9151\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 399s 7ms/sample - loss: 0.0973 - accuracy: 0.9676 - val_loss: 0.3770 - val_accuracy: 0.9156\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 514s 9ms/sample - loss: 0.0947 - accuracy: 0.9676 - val_loss: 0.4236 - val_accuracy: 0.9087\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 443s 7ms/sample - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.4095 - val_accuracy: 0.9176\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 493s 8ms/sample - loss: 0.0886 - accuracy: 0.9698 - val_loss: 0.4594 - val_accuracy: 0.9191\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 566s 9ms/sample - loss: 0.0924 - accuracy: 0.9687 - val_loss: 0.4651 - val_accuracy: 0.9149\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 301s 5ms/sample - loss: 0.0910 - accuracy: 0.9692 - val_loss: 0.4031 - val_accuracy: 0.9124\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 310s 5ms/sample - loss: 0.0836 - accuracy: 0.9709 - val_loss: 0.4612 - val_accuracy: 0.9185\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 344s 6ms/sample - loss: 0.0900 - accuracy: 0.9699 - val_loss: 0.4590 - val_accuracy: 0.9143\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 311s 5ms/sample - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.4953 - val_accuracy: 0.9183\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 296s 5ms/sample - loss: 0.0858 - accuracy: 0.9711 - val_loss: 0.5288 - val_accuracy: 0.9164\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 299s 5ms/sample - loss: 0.0863 - accuracy: 0.9717 - val_loss: 0.5575 - val_accuracy: 0.9179\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 347s 6ms/sample - loss: 0.0801 - accuracy: 0.9730 - val_loss: 0.4939 - val_accuracy: 0.9169\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 362s 6ms/sample - loss: 0.0839 - accuracy: 0.9717 - val_loss: 0.5194 - val_accuracy: 0.9200\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 339s 6ms/sample - loss: 0.0852 - accuracy: 0.9718 - val_loss: 0.4737 - val_accuracy: 0.9221\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 290s 5ms/sample - loss: 0.0808 - accuracy: 0.9736 - val_loss: 0.5255 - val_accuracy: 0.9189\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 307s 5ms/sample - loss: 0.0786 - accuracy: 0.9744 - val_loss: 0.5589 - val_accuracy: 0.9198\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 378s 6ms/sample - loss: 0.0781 - accuracy: 0.9737 - val_loss: 0.4818 - val_accuracy: 0.9092\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 483s 8ms/sample - loss: 0.0761 - accuracy: 0.9749 - val_loss: 0.5724 - val_accuracy: 0.9121\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 415s 7ms/sample - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.5430 - val_accuracy: 0.9165\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 424s 7ms/sample - loss: 0.0781 - accuracy: 0.9744 - val_loss: 0.5627 - val_accuracy: 0.9155\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 469s 8ms/sample - loss: 0.0768 - accuracy: 0.9756 - val_loss: 0.5093 - val_accuracy: 0.9178\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 517s 9ms/sample - loss: 0.0760 - accuracy: 0.9762 - val_loss: 0.5646 - val_accuracy: 0.9174\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 525s 9ms/sample - loss: 0.0798 - accuracy: 0.9752 - val_loss: 0.5133 - val_accuracy: 0.9168\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 385s 6ms/sample - loss: 0.0730 - accuracy: 0.9763 - val_loss: 0.5385 - val_accuracy: 0.9189\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 277s 5ms/sample - loss: 0.0759 - accuracy: 0.9760 - val_loss: 0.5580 - val_accuracy: 0.9165\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 299s 5ms/sample - loss: 0.0695 - accuracy: 0.9770 - val_loss: 0.6407 - val_accuracy: 0.9138\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 472s 8ms/sample - loss: 0.0728 - accuracy: 0.9756 - val_loss: 0.4959 - val_accuracy: 0.9162\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 395s 7ms/sample - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.5449 - val_accuracy: 0.9121\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 412s 7ms/sample - loss: 0.0724 - accuracy: 0.9763 - val_loss: 0.6254 - val_accuracy: 0.9155\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 450s 7ms/sample - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.6573 - val_accuracy: 0.9174\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 373s 6ms/sample - loss: 0.0736 - accuracy: 0.9766 - val_loss: 0.5267 - val_accuracy: 0.9176\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 257s 4ms/sample - loss: 0.0706 - accuracy: 0.9774 - val_loss: 0.6785 - val_accuracy: 0.9210\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 260s 4ms/sample - loss: 0.0729 - accuracy: 0.9775 - val_loss: 0.5435 - val_accuracy: 0.9187\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 260s 4ms/sample - loss: 0.0699 - accuracy: 0.9785 - val_loss: 0.5484 - val_accuracy: 0.9180\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 284s 5ms/sample - loss: 0.0690 - accuracy: 0.9783 - val_loss: 0.6551 - val_accuracy: 0.9198\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 262s 4ms/sample - loss: 0.0655 - accuracy: 0.9785 - val_loss: 0.5810 - val_accuracy: 0.9170\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 261s 4ms/sample - loss: 0.0669 - accuracy: 0.9781 - val_loss: 0.6969 - val_accuracy: 0.9132\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 261s 4ms/sample - loss: 0.0732 - accuracy: 0.9778 - val_loss: 0.5861 - val_accuracy: 0.9210\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 261s 4ms/sample - loss: 0.0692 - accuracy: 0.9782 - val_loss: 0.5706 - val_accuracy: 0.9202\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 261s 4ms/sample - loss: 0.0689 - accuracy: 0.9788 - val_loss: 0.6106 - val_accuracy: 0.9125\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 275s 5ms/sample - loss: 0.0669 - accuracy: 0.9794 - val_loss: 0.5795 - val_accuracy: 0.9198\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 291s 5ms/sample - loss: 0.0663 - accuracy: 0.9786 - val_loss: 0.5120 - val_accuracy: 0.9175\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 296s 5ms/sample - loss: 0.0583 - accuracy: 0.9809 - val_loss: 0.5816 - val_accuracy: 0.9173\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 313s 5ms/sample - loss: 0.0644 - accuracy: 0.9798 - val_loss: 0.6044 - val_accuracy: 0.9145\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 447s 7ms/sample - loss: 0.0669 - accuracy: 0.9796 - val_loss: 0.8067 - val_accuracy: 0.9177\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 326s 5ms/sample - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.6536 - val_accuracy: 0.9196\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 306s 5ms/sample - loss: 0.0650 - accuracy: 0.9801 - val_loss: 0.6206 - val_accuracy: 0.9181\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 294s 5ms/sample - loss: 0.0617 - accuracy: 0.9808 - val_loss: 0.6767 - val_accuracy: 0.9152\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 285s 5ms/sample - loss: 0.0644 - accuracy: 0.9800 - val_loss: 0.5880 - val_accuracy: 0.9155\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 284s 5ms/sample - loss: 0.0647 - accuracy: 0.9803 - val_loss: 0.6191 - val_accuracy: 0.9192\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 293s 5ms/sample - loss: 0.0583 - accuracy: 0.9811 - val_loss: 0.6715 - val_accuracy: 0.9196\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 299s 5ms/sample - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.7787 - val_accuracy: 0.9198\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 296s 5ms/sample - loss: 0.0627 - accuracy: 0.9807 - val_loss: 0.6922 - val_accuracy: 0.9166\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 295s 5ms/sample - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.6781 - val_accuracy: 0.9179\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 289s 5ms/sample - loss: 0.0666 - accuracy: 0.9794 - val_loss: 0.6937 - val_accuracy: 0.9164\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 290s 5ms/sample - loss: 0.0614 - accuracy: 0.9814 - val_loss: 0.5956 - val_accuracy: 0.9180\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 284s 5ms/sample - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.6814 - val_accuracy: 0.9208\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 285s 5ms/sample - loss: 0.0597 - accuracy: 0.9813 - val_loss: 0.6726 - val_accuracy: 0.9197\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 285s 5ms/sample - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.6658 - val_accuracy: 0.9204\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 284s 5ms/sample - loss: 0.0714 - accuracy: 0.9794 - val_loss: 0.5627 - val_accuracy: 0.9165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x219cab19e48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_images_reshape, train_labels,\n",
    "          validation_data=(test_images_reshape, test_labels),\n",
    "          epochs = 100,\n",
    "          batch_size = 25,\n",
    "          callbacks = [TensorBoard(\n",
    "              log_dir = os.path.join('fitlog','wide'),\n",
    "              histogram_freq = 1,\n",
    "              profile_batch = 100000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
